# My completed laboratory for KPI
In this repository, I posted my version of the laboratory work in open access.

Each folder contains several files:
> 1) Date folder (in which the dataset is stored)
> 2) Main file (code of our program)
> 3) The task that was posted by the teacher

Each main file is a file as type **"IPYNB" (.ipynb)** that was pre-launched, and you can see it running.

# There are 5 labs in total

  ## 1. Numpy & Pandas
  
  Numpy
  > NumPy plays a crucial role in machine learning as a foundational library, providing efficient and versatile tools for handling numerical data. Its multi-dimensional arrays enable seamless storage and manipulation of datasets, making it a cornerstone for data preprocessing, feature extraction, and model training. NumPy's mathematical functions and broadcasting capabilities facilitate complex computations essential for algorithm implementation. Integrating seamlessly with other machine learning libraries, NumPy forms an integral part of the data manipulation and numerical computation pipeline that underpins various stages of the machine learning workflow.
> 
  Pandas
 > Pandas is a vital library in the field of machine learning, offering powerful tools for data manipulation and analysis. With its DataFrame and Series data structures, Pandas simplifies data handling, transformation, and exploration, making it indispensable for tasks like data preprocessing, cleaning, and feature engineering. Its functionalities for grouping, aggregation, and merging are pivotal in preparing data for model training. Furthermore, Pandas' seamless integration with other machine learning libraries streamlines the process of loading, manipulating, and transforming datasets, contributing significantly to the efficiency and effectiveness of the machine learning pipeline.
    
  ## 2. Metrics
> Machine learning metrics serve as vital evaluation tools for assessing the performance of models. These metrics provide quantitative insights into a model's effectiveness in making predictions. Metrics such as accuracy, precision, recall, and F1-score are essential for classification tasks, measuring the correctness and completeness of predictions. For regression tasks, metrics like mean squared error (MSE) and root mean squared error (RMSE) gauge the disparity between predicted and actual values. Area under the receiver operating characteristic curve (AUC-ROC) and area under the precision-recall curve (AUC-PR) are crucial for assessing model performance across different probability thresholds. These metrics collectively aid in model selection, hyperparameter tuning, and understanding the trade-offs between different aspects of model performance.
> 
<img src="http://kflu.github.io/2016/08/26/2016-08-26-visualizing-precision-recall/2016-08-26-visualizing-precision-recall-1.png"/>

  ## 3. Decision Tree

  ## 4. K-Nearest Neighbors Method

  ## 5. Clustering

![catworking](https://github.com/AntonMitchenko/kpi_ml_labs/blob/main/assets/image/1621725540_catworking.gif)

